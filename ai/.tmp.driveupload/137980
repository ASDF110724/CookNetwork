import os
import json

from fastapi import APIRouter, Body
from dotenv import load_dotenv

from typing import List
from langchain.docstore.document import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from dotenv import load_dotenv

print(load_dotenv())


def load_json_documents(directory: str) -> List[Document]:
    documents = []
    for filename in os.listdir(directory):
        if filename.endswith('.json'):
            file_path = os.path.join(directory, filename)
            with open(file_path, 'r', encoding='utf-8') as file:
                data = json.load(file)
                print(data.__len__())
                content = json.dumps(data, ensure_ascii=False, indent=2)
                # documents.append(Document(page_content=content, metadata={"source": file_path}))
                documents.append(content)
    return documents


# def split_documents(documents: list[Document]) -> list[Document]:
#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)
#     return text_splitter.split_documents(documents)


def create_vector_store(texts):
    # 단어 수준의 임베딩에 적합한 모델 사용
    embeddings = OpenAIEmbeddings(model='text-embedding-3-large')
    vector_store = FAISS.from_documents(texts, embeddings)
    # vector_store = Chroma.from_documents(documents=texts, embedding=embeddings)
    return vector_store


def format_docs(docs):
    return '\n\n'.join(doc.page_content for doc in docs)


def setup_rag(vector_store):
    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={"k": 5})

    template = """
    질문에 대한 답을 밑의 내용에서 찾아서 한국어로 정리해서 레시피에 대한 설명으로 답하세요.
    밑의 내용에 정확한 대답이 없으면 "주어진 정보로는 답변할 수 없습니다."라고 말하세요.

    {context}

    질문에 대한 답을 알 수 없다면, "주어진 정보로는 답변할 수 없습니다."라고 말하세요.

    질문: {question}
    대답:"""

    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.1)

    qa_chain = (
            RunnableParallel(
                {"context": retriever, "question": RunnablePassthrough()}
            )
            | QA_CHAIN_PROMPT
            | llm
            | StrOutputParser()
    )

    return qa_chain, retriever


def qa_chain_with_sources(qa_chain, retriever, query):
    result = qa_chain.invoke(query)
    docs = retriever.invoke(query)
    return {"result": result, "source_documents": docs}

router = APIRouter()

directory = "./Recipe_Contents"

# JSON 문서 로드 및 처리
documents = load_json_documents(directory)
# texts = split_documents(documents)
print(documents)
# print(f"{len(texts)}개의 텍스트 청크를 생성했습니다.")

vector_store = create_vector_store(documents)
print("벡터 저장소 생성 완료")

qa_chain, retriever = setup_rag(vector_store)
print("RAG 설정 완료")

@router.post("/recipes")
async def recipes_answer(query: dict = Body(...)):



    result = qa_chain_with_sources(qa_chain, retriever, query)
    # print(result)

    print(f"\n질문: {query}")
    print(f"답변: {result['result']}")

    print("\n참고한 문서:")
    for doc in result['source_documents']:
        print(f"- {doc.page_content[:100]}...")  # 첫 100자만 출력


# @router.post("/search")