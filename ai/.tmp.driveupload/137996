import os
import json

from fastapi import APIRouter, Body
from dotenv import load_dotenv

from typing import List
from langchain.docstore.document import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from dotenv import load_dotenv

print(load_dotenv())

def parse_content(content):
    parsed_content = {}

    # 기본 정보 추가 (값이 있는 경우에만)
    for key in ["제목", "설명", "serving", "조리시간", "난이도", "재료", "조리도구", "조리순서"]:
        if content.get(key):
            if key == "재료":
                if isinstance(content[key], list):
                    parsed_content[key] = content[key]
                elif isinstance(content[key], dict):
                    ingredients = []
                    for category, ingredients in content[key].items():
                        ingredients.extend([f"{ing['이름']} {ing['양']}" for ing in ingredients])
                    parsed_content[key] = ingredients
            elif key == "조리순서":
                parsed_content[key] = [step["설명"] for step in content[key]]
            else:
                parsed_content[key] = content[key]
    return parsed_content

def load_json_documents(directory: str) -> List[Document]:
    documents = []
    for filename in os.listdir(directory):
        if filename.endswith('.json'):
            file_path = os.path.join(directory, filename)
            with open(file_path, 'r', encoding='utf-8') as file:
                data = json.load(file)
                # content = json.loads(json.dumps(data, ensure_ascii=False, indent=2))
                # print(content)
                # documents.append(Document(page_content=content, metadata={"source": file_path}))
                documents.append(parse_content(data))
    return documents


# def split_documents(documents: list[Document]) -> list[Document]:
#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)
#     return text_splitter.split_documents(documents)


def create_vector_store(texts):
    # 단어 수준의 임베딩에 적합한 모델 사용
    embeddings = OpenAIEmbeddings(model='text-embedding-3-large')
    # vector_store = FAISS.from_documents(texts, embeddings)
    vector_store = FAISS.from_texts(texts, embeddings)
    # vector_store = Chroma.from_documents(documents=texts, embedding=embeddings)
    return vector_store


def format_docs(docs):
    return '\n\n'.join(doc.page_content for doc in docs)


def setup_rag(vector_store):
    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={"k": 5})

    template = """
    질문에 대한 답을 밑의 내용에서 찾아서 한국어로 정리해서 레시피에 대한 설명으로 답하세요.
    밑의 내용에 정확한 대답이 없으면 "주어진 정보로는 답변할 수 없습니다."라고 말하세요.

    {context}

    질문에 대한 답을 알 수 없다면, "주어진 정보로는 답변할 수 없습니다."라고 말하세요.

    질문: {question}
    대답:"""

    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.1)

    qa_chain = (
            RunnableParallel(
                {"context": retriever, "question": RunnablePassthrough()}
            )
            | QA_CHAIN_PROMPT
            | llm
            | StrOutputParser()
    )

    return qa_chain, retriever


def qa_chain_with_sources(qa_chain, retriever, query):
    result = qa_chain.invoke(query)
    docs = retriever.invoke(query)
    return {"result": result, "source_documents": docs}

router = APIRouter()

directory = "./Recipe_Contents"

# JSON 문서 로드 및 처리
documents = load_json_documents(directory)
# texts = split_documents(documents)
print(documents)
# print(f"{len(texts)}개의 텍스트 청크를 생성했습니다.")

vector_store = create_vector_store(documents)
print("벡터 저장소 생성 완료")

qa_chain, retriever = setup_rag(vector_store)
print("RAG 설정 완료")

@router.post("/recipes")
async def recipes_answer(query: dict = Body(...)):



    result = qa_chain_with_sources(qa_chain, retriever, query)
    # print(result)

    print(f"\n질문: {query}")
    print(f"답변: {result['result']}")

    print("\n참고한 문서:")
    for doc in result['source_documents']:
        print(f"- {doc.page_content[:100]}...")  # 첫 100자만 출력


# @router.post("/search")